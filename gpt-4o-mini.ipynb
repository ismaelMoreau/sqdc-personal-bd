{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"products\": [\n",
      "    {\n",
      "      \"name\": \"L'Bon voisin\",\n",
      "      \"brand\": \"Fleurs de Lise\",\n",
      "      \"species\": \"Sativa\",\n",
      "      \"variety\": \"Alien Cookies\",\n",
      "      \"genetics\": \"Girl Scout Cookies x Alien Dog\",\n",
      "      \"format\": \"1 g\",\n",
      "      \"method_of_curing\": \"Humid curing, hand-trimmed, followed by dry curing\",\n",
      "      \"effects\": [\n",
      "        \"Euphoria\",\n",
      "        \"Relaxation\",\n",
      "        \"Joy\"\n",
      "      ],\n",
      "      \"effect_onset_time\": \"Approximately 2 minutes after inhalation\",\n",
      "      \"cultivation_method\": \"Hydroponic indoor cultivation\",\n",
      "      \"location\": \"Sainte-Agathe-des-Monts, Québec\",\n",
      "      \"warning_message\": \"Store cannabis products securely to avoid accidental consumption.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Le P'ti Phéno\",\n",
      "      \"brand\": \"Pecko\",\n",
      "      \"species\": \"1:1 - Rotatif\",\n",
      "      \"cultivation_method\": \"Micro-production in Quebec\",\n",
      "      \"format\": \"1 g\",\n",
      "      \"effects\": [\n",
      "        \"Calm\",\n",
      "        \"Relaxing\"\n",
      "      ],\n",
      "      \"effect_onset_time\": \"90 seconds to 5 minutes\",\n",
      "      \"additional_info\": [\n",
      "        \"Cultivated indoors\",\n",
      "        \"Top Cola only\",\n",
      "        \"2 weeks of cold curing\",\n",
      "        \"Hand-trimmed and packaged\",\n",
      "        \"Dried upside down\",\n",
      "        \"Non-irradiated\"\n",
      "      ],\n",
      "      \"warning_message\": \"Store cannabis products securely to avoid accidental consumption.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Le P'ti Phéno\",\n",
      "      \"brand\": \"Pecko\",\n",
      "      \"species\": \"Indica in rotation\",\n",
      "      \"cultivation_method\": \"Micro-production in Quebec\",\n",
      "      \"format\": \"1 g\",\n",
      "      \"effects\": [\n",
      "        \"Calm\",\n",
      "        \"Relaxing\"\n",
      "      ],\n",
      "      \"effect_onset_time\": \"90 seconds to 5 minutes\",\n",
      "      \"additional_info\": [\n",
      "        \"Cultivated indoors\",\n",
      "        \"Top Cola only\",\n",
      "        \"2 weeks of cold curing\",\n",
      "        \"Hand-trimmed and packaged\",\n",
      "        \"Dried upside down\",\n",
      "        \"Non-irradiated\"\n",
      "      ],\n",
      "      \"warning_message\": \"Store cannabis products securely to avoid accidental consumption.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Set the API key and model name\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "FOLDER_PATH = \"pdf_products/Fleurs Séchées 1g\"\n",
    "API_KEY = os.environ.get(\"sqdc_api_key\")\n",
    "MONGODB_URI = os.environ.get(\"mongodb_uri\")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# MongoDB client setup\n",
    "mongo_client = MongoClient(MONGODB_URI)\n",
    "db = mongo_client['your_database_name']  # Replace with your database name\n",
    "collection = db['your_collection_name']  # Replace with your collection name\n",
    "\n",
    "# Function to encode image as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to insert schema into MongoDB\n",
    "def insert_schema_into_mongo(schema, image_name):\n",
    "    document = {\n",
    "        \"image_name\": image_name,\n",
    "        \"schema\": schema\n",
    "    }\n",
    "    collection.insert_one(document)\n",
    "\n",
    "# Get all .png files in the specified folder\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.endswith('.png')]\n",
    "\n",
    "# Process each image individually\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(FOLDER_PATH, image_file)\n",
    "    base64_image = encode_image(image_path)\n",
    "    \n",
    "    # Create the message for the current image\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a database specialist assistant, that will responds only mongodb schema!\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    ]\n",
    "    \n",
    "    # Send the request to OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    # Get the generated MongoDB schema for the current image\n",
    "    schema = response.choices[0].message.content\n",
    "    \n",
    "    # Insert the schema into MongoDB\n",
    "    insert_schema_into_mongo(schema, image_file)\n",
    "    \n",
    "    # Print the inserted schema for verification\n",
    "    print(f\"Inserted MongoDB Schema for {image_file}:\\n\")\n",
    "    print(schema)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_schema_to_json(schema, collection_name):\n",
    "    filename = f\"{collection_name}_fields.json\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(schema, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Schema for collection '{collection_name}' saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image is below 20 MB in size and is of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'sanitizer_server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     32\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     33\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     34\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase64_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m     35\u001b[0m         ]}\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Send the request to OpenAI API\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Print the generated MongoDB schema\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/sqdc/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sqdc/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py:646\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sqdc/.venv/lib/python3.12/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/sqdc/.venv/lib/python3.12/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sqdc/.venv/lib/python3.12/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1054\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image is below 20 MB in size and is of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'sanitizer_server_error'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the API key and model name\n",
    "#collection = \"Fleurs Séchées  1g\"\n",
    "collection = \"Hashish\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "FOLDER_PATH = f\"pdf_products/{collection}\"\n",
    "API_KEY = os.environ.get(\"sqdc_api_key\")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Function to encode image as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Get all .png files in the specified folder\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith('.png')]\n",
    "\n",
    "# Encode images and create the messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a database specialist assistant, that will responds only mongodb schema!\"}\n",
    "    \n",
    "]\n",
    "messages.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"from all images, read it and make a mongodb shema with most relevant informations\"}]})\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(FOLDER_PATH, image_file)\n",
    "    base64_image = encode_image(image_path)\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    )\n",
    "\n",
    "# Send the request to OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Print the generated MongoDB schema\n",
    "print(response.choices[0].message.content)\n",
    "save_schema_to_json(response.choices[0].message.content,collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici un schéma MongoDB en français basé sur les informations des images fournies :\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"produits\": [\n",
      "    {\n",
      "      \"nom\": \"CBD 50 Capsules\",\n",
      "      \"format\": \"30 Capsules\",\n",
      "      \"dosage\": \"50mg de CBD/unité\",\n",
      "      \"effets_potentiels\": [\"Calme\", \"Relaxant\"],\n",
      "      \"temps_appartion_effets\": \"Jusqu'à 60 minutes après ingestion et parfois davantage\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Gélules équilibrées\",\n",
      "      \"format\": \"30 x 2-4 MG 1:1 THC:CBD\",\n",
      "      \"effets_potentiels\": [\"Créativité\", \"Appétit\", \"Calme\"],\n",
      "      \"temps_appartion_effets\": \"Jusqu'à 60 minutes après ingestion et parfois davantage\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Gélules de Pink Kush\",\n",
      "      \"format\": \"30 Softgels\",\n",
      "      \"effets_potentiels\": [\"Créativité\", \"Appétit\", \"Calme\"],\n",
      "      \"temps_appartion_effets\": \"De 90 secondes à 5 minutes après inhalation\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Capsules à la rosine\",\n",
      "      \"format\": \"30 capsules\",\n",
      "      \"effets_potentiels\": [\"Joie\", \"Calme\", \"Relaxation\"],\n",
      "      \"temps_appartion_effets\": \"Jusqu'à 60 minutes après ingestion et parfois davantage\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Gouttes de Hashish Rosin\",\n",
      "      \"format\": \"50 x 0.25g\",\n",
      "      \"effets_potentiels\": [\"Euphorie\", \"Célèbre\", \"Appétit\"],\n",
      "      \"temps_appartion_effets\": \"60 minutes ou plus\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Gélules CBD 750 mg\",\n",
      "      \"format\": \"15 unités\",\n",
      "      \"dosage\": \"50 mg de CBD par gélule\",\n",
      "      \"effets_potentiels\": [\"Calme\", \"Relaxation\"],\n",
      "      \"temps_appartion_effets\": \"Après 30 minutes\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"CBD Cap30\",\n",
      "      \"format\": \"50 capsules\",\n",
      "      \"effets_potentiels\": [\"Relaxant\", \"Détente\"],\n",
      "      \"temps_appartion_effets\": \"90 secondes à 5 minutes après inhalation\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Tweed CBD\",\n",
      "      \"format\": \"30 x 10 mg\",\n",
      "      \"effets_potentiels\": [\"Calme\", \"Relaxation\", \"Sommeil\"],\n",
      "      \"temps_appartion_effets\": \"Jusqu'à 60 minutes après ingestion et parfois davantage\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Rêver\",\n",
      "      \"format\": \"30 capsules\",\n",
      "      \"effets_potentiels\": [\"Calme\", \"Inspiration\", \"Concentration\"],\n",
      "      \"temps_appartion_effets\": \"Jusqu'à 60 minutes après ingestion et parfois davantage\"\n",
      "    },\n",
      "    {\n",
      "      \"nom\": \"Capsules riches en THC\",\n",
      "      \"format\": \"15 capsules\",\n",
      "      \"effets_potentiels\": [\"Créativité\", \"Stimulation de l'appétit\"],\n",
      "      \"temps_appartion_effets\": \"Après 30 minutes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Ce schéma contient des informations sur chaque produit, y compris le nom, le format, le dosage, les effets potentiels et le temps d'apparition des effets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the API key and model name\n",
    "collection = \"Capsules\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "FOLDER_PATH = f\"pdf_products/{collection}\"\n",
    "API_KEY = os.environ.get(\"sqdc_api_key\")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Function to encode image as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to resize image proportionally\n",
    "def resize_image(image_path):\n",
    "    resized_image_path = os.path.join(FOLDER_PATH, f\"resized_{os.path.basename(image_path)}\")\n",
    "    \n",
    "    if os.path.exists(resized_image_path):\n",
    "        return resized_image_path\n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        if width < height:\n",
    "            if width > 768:\n",
    "                ratio = 768 / width\n",
    "                new_width = 768\n",
    "                new_height = int(height * ratio)\n",
    "                if new_height > 2000:\n",
    "                    ratio = 2000 / height\n",
    "                    new_width = int(width * ratio)\n",
    "                    new_height = 2000\n",
    "            elif height > 2000:\n",
    "                ratio = 2000 / height\n",
    "                new_width = int(width * ratio)\n",
    "                new_height = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        else:\n",
    "            if height > 768:\n",
    "                ratio = 768 / height\n",
    "                new_height = 768\n",
    "                new_width = int(width * ratio)\n",
    "                if new_width > 2000:\n",
    "                    ratio = 2000 / width\n",
    "                    new_height = int(height * ratio)\n",
    "                    new_width = 2000\n",
    "            elif width > 2000:\n",
    "                ratio = 2000 / width\n",
    "                new_width = 2000\n",
    "                new_height = int(height * ratio)\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        \n",
    "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        resized_image_path = os.path.join(FOLDER_PATH, f\"resized_{os.path.basename(image_path)}\")\n",
    "        img.save(resized_image_path)\n",
    "        return resized_image_path\n",
    "        \n",
    "\n",
    "# Get all .png files in the specified folder\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith('.png')]\n",
    "\n",
    "# Encode images and create the messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a frensh database specialist assistant, that will responds only mongodb schema translated in frensh!\"}\n",
    "]\n",
    "messages.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"from all images, read it and make a mongodb shema with all possible relevant informations\"}]})\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(FOLDER_PATH, image_file)\n",
    "    resized_image_path = resize_image(image_path)\n",
    "    base64_image = encode_image(resized_image_path)\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    )\n",
    "\n",
    "# Send the request to OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Print the generated MongoDB schema\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Function to save schema to JSON\n",
    "def save_schema_to_text(schema, collection_name):\n",
    "    output_path = os.path.join(FOLDER_PATH, f\"{collection_name}_schema.txt\")\n",
    "    with open(output_path, \"w\") as text_file:\n",
    "        text_file.write(schema)\n",
    "\n",
    "save_schema_to_text(response.choices[0].message.content, collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the detailed information extracted from the images, here is a comprehensive MongoDB schema for the various types of hashish products. Each schema is designed to capture the relevant attributes of the products, including their characteristics, effects, and production methods.\n",
      "\n",
      "### MongoDB Schema\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"products\": [\n",
      "    {\n",
      "      \"name\": \"Hash #1\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"1g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun à noir\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Calme\", \"Relaxation\", \"Euphorie\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"QcGold\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Habibi Kush\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3.5g\",\n",
      "      \"variety\": \"OG Kush\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun foncé à noir\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Énergie\", \"Appétit\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Nordique Royale\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Attache ta tuque\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3g\",\n",
      "      \"variety\": \"Medellin\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Blond à brun clair\",\n",
      "        \"external\": \"Brun clair à brun foncé\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Cérébral\", \"Sommeil\"],\n",
      "      \"appearance_time\": \"2 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Affinage humide\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Origine Nature\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich Afghan Noir\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Détente\", \"Relaxation\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Sans solvant (mécanique)\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Tremblant\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich Pressé\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"2g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Blond à brun clair\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Joie\", \"Stimulant\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Exka\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Balle de Hash\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"2g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun foncé à noir\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Heureux\", \"Relax\", \"Cérébral\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Sans solvant\",\n",
      "        \"cultivation\": \"Colombie-Britannique\"\n",
      "      },\n",
      "      \"brand\": \"Simply Bare\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschtag CBD\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"1g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun clair à brun foncé\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Relaxation\", \"Calme\", \"Détente\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec et CO2\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Exka\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich de CBD\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3.5g\",\n",
      "      \"variety\": \"Cherry Blossom\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Calme\", \"Joie\", \"Appétit\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec, CO2\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"De La Ferme\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich Libanais\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3.5g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Relaxation\", \"Calme\", \"Joie\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Sans solvant\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Rubicon\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"OG Hawaïenne\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3g\",\n",
      "      \"variety\": \"Pineapple Express X OG Kush\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Blond à brun clair\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Créativité\", \"Joie\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Nordique Royale\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich Eiffel\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Relaxation\", \"Détente\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Sans solvant\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"R'Belle\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschtag Hash de Rosine\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"2g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun clair à brun foncé\"\n",
      "      },\n",
      "      \"texture\": \"Dur à friable\",\n",
      "      \"effects\": [\"Rire\", \"Vivification\", \"Calme\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec et CO2\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Exka\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich de Zsweet\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3.5g\",\n",
      "      \"variety\": \"Zsweet Insanity\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Joie\", \"Énergie\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"C02\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"5 Points\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Onyx Haschich\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"2g\",\n",
      "      \"variety\": \"Blend\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun foncé à noir\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Dur à friable\",\n",
      "      \"effects\": [\"Énergie\", \"Créativité\", \"Sociabilité\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"C02, sans solvant, tamisage à sec\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Ono\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Héritage\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3.5g\",\n",
      "      \"variety\": \"Citroil X Umpqua\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Énergie\", \"Stimulation\", \"Inspiration\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Bud\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Boule de Laine Haschich\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"2g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Blond à brun clair\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Relaxation\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Sans solvant et mécanique\",\n",
      "        \"cultivation\": \"N/A\"\n",
      "      },\n",
      "      \"brand\": \"Pure Laine\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschtag Hash de Noé\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3.5g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun clair à brun foncé\"\n",
      "      },\n",
      "      \"texture\": \"Dur à friable\",\n",
      "      \"effects\": [\"Rire\", \"Vivification\", \"Calme\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Tamisage à sec et CO2\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Exka\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Le Kush X\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"2g\",\n",
      "      \"variety\": \"Kush Cookies\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Blond à brun clair\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Dur à friable\",\n",
      "      \"effects\": [\"Joie\", \"Appétit\", \"Calme\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Sans solvant\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"Nordique Royale\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich Eiffel\",\n",
      "      \"type\": \"Hashish\",\n",
      "      \"format\": \"3g\",\n",
      "      \"variety\": \"Mélange\",\n",
      "      \"colors\": {\n",
      "        \"internal\": \"Brun clair à brun foncé\",\n",
      "        \"external\": \"Brun foncé à noir\"\n",
      "      },\n",
      "      \"texture\": \"Malléable à résineux\",\n",
      "      \"effects\": [\"Euphorie\", \"Relaxation\", \"Détente\"],\n",
      "      \"appearance_time\": \"90 secondes à 5 minutes après inhalation\",\n",
      "      \"production\": {\n",
      "        \"method\": \"Sans solvant\",\n",
      "        \"cultivation\": \"Québec\"\n",
      "      },\n",
      "      \"brand\": \"R'Belle\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation\n",
      "- Each product is represented as a document within the `products` array.\n",
      "- Attributes include `name`, `type`, `format`, `variety`, `colors`, `texture`, `effects`, `appearance_time`, `production`, and `brand`.\n",
      "- The `colors` attribute is an object containing `internal` and `external` color variations.\n",
      "- The `production` attribute includes the method of production and cultivation details.\n",
      "\n",
      "This schema can be used to store and retrieve detailed information about various hashish products in a MongoDB database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the API key and model name\n",
    "collection = \"Hashish\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "FOLDER_PATH = f\"pdf_products/{collection}\"\n",
    "API_KEY = os.environ.get(\"sqdc_api_key\")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Function to encode image as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to resize image proportionally\n",
    "def resize_image(image_path):\n",
    "    resized_image_path = os.path.join(FOLDER_PATH, f\"resized_{os.path.basename(image_path)}\")\n",
    "\n",
    "    if os.path.exists(resized_image_path):\n",
    "        return resized_image_path\n",
    "    \n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        if width <= 2000 and height <= 2000 and (width <= 768 or height <= 768):\n",
    "            return image_path  # No need to resize\n",
    "        \n",
    "        if width < height:\n",
    "            if width > 768:\n",
    "                ratio = 768 / width\n",
    "                new_width = 768\n",
    "                new_height = int(height * ratio)\n",
    "                if new_height > 2000:\n",
    "                    ratio = 2000 / height\n",
    "                    new_width = int(width * ratio)\n",
    "                    new_height = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        else:\n",
    "            if height > 768:\n",
    "                ratio = 768 / height\n",
    "                new_height = 768\n",
    "                new_width = int(width * ratio)\n",
    "                if new_width > 2000:\n",
    "                    ratio = 2000 / width\n",
    "                    new_height = int(height * ratio)\n",
    "                    new_width = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        \n",
    "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        img.save(resized_image_path)\n",
    "        return resized_image_path\n",
    "\n",
    "# Get all .png files in the specified folder\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith('.png') and not f.startswith('resized_')]\n",
    "\n",
    "# Encode images and create the messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a database specialist assistant.\"}\n",
    "]\n",
    "messages.append({\"role\": \"user\", \"content\": \"Analyze all the following images and extract as much detailed information as possible. Use this information to create a validation MongoDB schema for future Insert, even if the schema is not perfectly structured. Prioritize the richness of the data extracted from the images.\"})\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(FOLDER_PATH, image_file)\n",
    "    resized_image_path = resize_image(image_path)\n",
    "    base64_image = encode_image(resized_image_path)\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    )\n",
    "\n",
    "# Send the request to OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Print the generated MongoDB schema\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Function to save schema to a text file\n",
    "def save_schema_to_text(schema, collection_name):\n",
    "    output_path = os.path.join(FOLDER_PATH, f\"{collection_name}_schema.txt\")\n",
    "    with open(output_path, \"w\") as text_file:\n",
    "        text_file.write(schema)\n",
    "\n",
    "save_schema_to_text(response.choices[0].message.content, collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information extracted from the images, here is a proposed MongoDB schema for the hashish products:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"hashish_products\": [\n",
      "    {\n",
      "      \"name\": \"Hash #1\",\n",
      "      \"brand\": \"QcGold\",\n",
      "      \"format\": \"1g\",\n",
      "      \"species\": \"Blend\",\n",
      "      \"color\": {\n",
      "        \"internal\": \"Dark brown\",\n",
      "        \"external\": \"Black\"\n",
      "      },\n",
      "      \"texture\": \"Malleable\",\n",
      "      \"effects\": [\"Calm\", \"Relaxation\", \"Euphoria\"],\n",
      "      \"appearance_time\": \"90 seconds to 5 minutes\",\n",
      "      \"cultivation\": {\n",
      "        \"method\": \"Hand-rolled\",\n",
      "        \"location\": \"Quebec\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Habibi Kush\",\n",
      "      \"brand\": \"Nordique Royale\",\n",
      "      \"format\": \"3.5g\",\n",
      "      \"species\": \"OG Kush\",\n",
      "      \"color\": {\n",
      "        \"internal\": \"Light brown to black\",\n",
      "        \"external\": \"Dark brown\"\n",
      "      },\n",
      "      \"texture\": \"Malleable\",\n",
      "      \"effects\": [\"Euphoria\", \"Energy\", \"Appetite\"],\n",
      "      \"appearance_time\": \"90 seconds to 5 minutes\",\n",
      "      \"cultivation\": {\n",
      "        \"method\": \"Dry sifting\",\n",
      "        \"location\": \"Quebec\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Attache ta tuque\",\n",
      "      \"brand\": \"Origine Nature\",\n",
      "      \"format\": \"3g\",\n",
      "      \"species\": \"Sativa\",\n",
      "      \"color\": {\n",
      "        \"internal\": \"Light brown\",\n",
      "        \"external\": \"Dark brown\"\n",
      "      },\n",
      "      \"texture\": \"Malleable\",\n",
      "      \"effects\": [\"Euphoria\", \"Cerebral\", \"Sleep\"],\n",
      "      \"appearance_time\": \"2 minutes after inhalation\",\n",
      "      \"cultivation\": {\n",
      "        \"method\": \"Hydroponic\",\n",
      "        \"location\": \"Quebec\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich Afghan Noir\",\n",
      "      \"brand\": \"Tremblant\",\n",
      "      \"format\": \"3g\",\n",
      "      \"species\": \"Blend\",\n",
      "      \"color\": {\n",
      "        \"internal\": \"Light brown to dark brown\",\n",
      "        \"external\": \"Dark brown to black\"\n",
      "      },\n",
      "      \"texture\": \"Malleable\",\n",
      "      \"effects\": [\"Relaxation\", \"Calm\"],\n",
      "      \"appearance_time\": \"90 seconds to 5 minutes\",\n",
      "      \"cultivation\": {\n",
      "        \"method\": \"Mechanical extraction\",\n",
      "        \"location\": \"Quebec\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschich Pressé\",\n",
      "      \"brand\": \"Tremblant\",\n",
      "      \"format\": \"2g\",\n",
      "      \"species\": \"Blend\",\n",
      "      \"color\": {\n",
      "        \"internal\": \"Light brown to dark brown\",\n",
      "        \"external\": \"Dark brown to black\"\n",
      "      },\n",
      "      \"texture\": \"Malleable\",\n",
      "      \"effects\": [\"Euphoria\", \"Joy\", \"Stimulation\"],\n",
      "      \"appearance_time\": \"90 seconds to 5 minutes\",\n",
      "      \"cultivation\": {\n",
      "        \"method\": \"Dry sifting\",\n",
      "        \"location\": \"Quebec\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Balle de Hash\",\n",
      "      \"brand\": \"Simply Bare\",\n",
      "      \"format\": \"2g\",\n",
      "      \"species\": \"Hybrid\",\n",
      "      \"color\": {\n",
      "        \"internal\": \"Dark brown to black\",\n",
      "        \"external\": \"Dark brown\"\n",
      "      },\n",
      "      \"texture\": \"Malleable\",\n",
      "      \"effects\": [\"Happy\", \"Relaxed\", \"Cerebral\"],\n",
      "      \"appearance_time\": \"90 seconds to 5 minutes\",\n",
      "      \"cultivation\": {\n",
      "        \"method\": \"No solvent\",\n",
      "        \"location\": \"British Columbia\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Haschtag CBD\",\n",
      "      \"brand\": \"Exka\",\n",
      "      \"format\": \"1g\",\n",
      "      \"species\": \"Blend\",\n",
      "      \"color\": {\n",
      "        \"internal\": \"Light brown to dark brown\",\n",
      "        \"external\": \"Light brown to dark brown\"\n",
      "      },\n",
      "      \"texture\": \"Malleable\",\n",
      "      \"effects\": [\"Relaxation\", \"Calm\", \"Detente\"],\n",
      "      \"appearance_time\": \"90 seconds to 5 minutes\",\n",
      "      \"cultivation\": {\n",
      "        \"method\": \"Dry sifting\",\n",
      "        \"location\": \"Quebec\"\n",
      "      }\n",
      "    }\n",
      "    // Additional products can be added in the same format\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- Each product is represented as a document within the `hashish_products` array.\n",
      "- Key attributes include `name`, `brand`, `format`, `species`, `color`, `texture`, `effects`, `appearance_time`, and `cultivation` details.\n",
      "- The `color` field is structured to include both internal and external colors.\n",
      "- The `effects` field is an array to accommodate multiple effects.\n",
      "- The `cultivation` field includes the method and location of cultivation.\n",
      "\n",
      "This schema can be expanded or modified based on additional products or specific requirements.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the API key and model name\n",
    "collection = \"Hashish\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "FOLDER_PATH = f\"pdf_products/{collection}\"\n",
    "API_KEY = os.environ.get(\"sqdc_api_key\")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Function to encode image as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to resize image proportionally\n",
    "def resize_image(image_path):\n",
    "    resized_image_path = os.path.join(FOLDER_PATH, f\"resized_{os.path.basename(image_path)}\")\n",
    "\n",
    "    if os.path.exists(resized_image_path):\n",
    "        return resized_image_path\n",
    "    \n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        if width <= 2000 and height <= 2000 and (width <= 768 or height <= 768):\n",
    "            return image_path  # No need to resize\n",
    "        \n",
    "        if width < height:\n",
    "            if width > 768:\n",
    "                ratio = 768 / width\n",
    "                new_width = 768\n",
    "                new_height = int(height * ratio)\n",
    "                if new_height > 2000:\n",
    "                    ratio = 2000 / height\n",
    "                    new_width = int(width * ratio)\n",
    "                    new_height = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        else:\n",
    "            if height > 768:\n",
    "                ratio = 768 / height\n",
    "                new_height = 768\n",
    "                new_width = int(width * ratio)\n",
    "                if new_width > 2000:\n",
    "                    ratio = 2000 / width\n",
    "                    new_height = int(height * ratio)\n",
    "                    new_width = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        \n",
    "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        img.save(resized_image_path)\n",
    "        return resized_image_path\n",
    "\n",
    "# Get all .png files in the specified folder\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith('.png') and not f.startswith('resized_')]\n",
    "\n",
    "# Encode images and create the messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Vous êtes un assistant spécialiste des bases de données.\"}\n",
    "]\n",
    "messages.append({\"role\": \"user\", \"content\": \"Analysez toutes les images suivantes et extrayez le plus d'informations détaillées possible de chacune. Utilisez ces informations pour créer un schéma MongoDB complet, même si le schéma n'est pas parfaitement structuré. Priorisez la richesse des données extraites des images.\"})\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(FOLDER_PATH, image_file)\n",
    "    resized_image_path = resize_image(image_path)\n",
    "    base64_image = encode_image(resized_image_path)\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    )\n",
    "\n",
    "# Send the request to OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Print the generated MongoDB schema\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Function to save schema to a text file\n",
    "def save_schema_to_text(schema, collection_name):\n",
    "    output_path = os.path.join(FOLDER_PATH, f\"{collection_name}_schema.txt\")\n",
    "    with open(output_path, \"w\") as text_file:\n",
    "        text_file.write(schema)\n",
    "\n",
    "save_schema_to_text(response.choices[0].message.content, collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici un schéma de validation MongoDB basé sur les informations extraites des images fournies. Ce schéma est conçu pour capturer les détails des produits de haschich, en mettant l'accent sur la richesse des données.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"bsonType\": \"object\",\n",
      "  \"required\": [\"nom\", \"format\", \"variete\", \"couleur_interne\", \"couleur_externe\", \"texture\", \"methode_extraction\", \"effets_potentiels\", \"temps_apparition\"],\n",
      "  \"properties\": {\n",
      "    \"nom\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Nom du produit\"\n",
      "    },\n",
      "    \"format\": {\n",
      "      \"bsonType\": \"double\",\n",
      "      \"description\": \"Poids du produit en grammes\"\n",
      "    },\n",
      "    \"variete\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Variété de cannabis utilisée\"\n",
      "    },\n",
      "    \"couleur_interne\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Couleur interne du produit\"\n",
      "    },\n",
      "    \"couleur_externe\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Couleur externe du produit\"\n",
      "    },\n",
      "    \"texture\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Texture du produit\"\n",
      "    },\n",
      "    \"methode_extraction\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Méthode d'extraction utilisée\"\n",
      "    },\n",
      "    \"effets_potentiels\": {\n",
      "      \"bsonType\": \"array\",\n",
      "      \"items\": {\n",
      "        \"bsonType\": \"string\"\n",
      "      },\n",
      "      \"description\": \"Liste des effets potentiels\"\n",
      "    },\n",
      "    \"temps_apparition\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Temps d'apparition des effets après inhalation\"\n",
      "    },\n",
      "    \"origine\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Lieu de culture ou de fabrication\"\n",
      "    },\n",
      "    \"avertissement\": {\n",
      "      \"bsonType\": \"string\",\n",
      "      \"description\": \"Message d'avertissement concernant la consommation\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "### Explication des champs :\n",
      "\n",
      "- **nom** : Le nom du produit de haschich.\n",
      "- **format** : Le poids du produit, généralement en grammes.\n",
      "- **variete** : La variété de cannabis utilisée pour produire le haschich.\n",
      "- **couleur_interne** : La couleur visible à l'intérieur du produit.\n",
      "- **couleur_externe** : La couleur visible à l'extérieur du produit.\n",
      "- **texture** : La texture du produit, par exemple, malléable ou résineux.\n",
      "- **methode_extraction** : La méthode utilisée pour extraire le haschich (ex. : sans solvant, tamisage à sec).\n",
      "- **effets_potentiels** : Une liste des effets que le produit peut avoir sur l'utilisateur.\n",
      "- **temps_apparition** : Le temps nécessaire pour que les effets se manifestent après inhalation.\n",
      "- **origine** : Le lieu où le produit a été cultivé ou fabriqué.\n",
      "- **avertissement** : Un message d'avertissement concernant la consommation du produit.\n",
      "\n",
      "Ce schéma peut être utilisé pour valider les documents dans une base de données MongoDB, garantissant que toutes les informations pertinentes sur les produits de haschich sont correctement enregistrées.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the API key and model name\n",
    "collection = \"Hashish\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "FOLDER_PATH = f\"pdf_products/{collection}\"\n",
    "API_KEY = os.environ.get(\"sqdc_api_key\")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Function to encode image as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to resize image proportionally\n",
    "def resize_image(image_path):\n",
    "    resized_image_path = os.path.join(FOLDER_PATH, f\"resized_{os.path.basename(image_path)}\")\n",
    "\n",
    "    if os.path.exists(resized_image_path):\n",
    "        return resized_image_path\n",
    "    \n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        if width <= 2000 and height <= 2000 and (width <= 768 or height <= 768):\n",
    "            return image_path  # No need to resize\n",
    "        \n",
    "        if width < height:\n",
    "            if width > 768:\n",
    "                ratio = 768 / width\n",
    "                new_width = 768\n",
    "                new_height = int(height * ratio)\n",
    "                if new_height > 2000:\n",
    "                    ratio = 2000 / height\n",
    "                    new_width = int(width * ratio)\n",
    "                    new_height = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        else:\n",
    "            if height > 768:\n",
    "                ratio = 768 / height\n",
    "                new_height = 768\n",
    "                new_width = int(width * ratio)\n",
    "                if new_width > 2000:\n",
    "                    ratio = 2000 / width\n",
    "                    new_height = int(height * ratio)\n",
    "                    new_width = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        \n",
    "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        img.save(resized_image_path)\n",
    "        return resized_image_path\n",
    "\n",
    "# Get all .png files in the specified folder\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith('.png') and not f.startswith('resized_')]\n",
    "\n",
    "# Encode images and create the messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Vous êtes un assistant spécialiste des bases de données.\"}\n",
    "]\n",
    "messages.append({\"role\": \"user\", \"content\": \"Analysez les images suivantes et extrayez le plus d'informations détaillées possible. Utilisez ces informations pour créer un schéma de validation MongoDB, même si le schéma n'est pas parfaitement structuré. Priorisez la richesse des données.\"})\n",
    "\n",
    "# Adjust the number of images to fit within the token limit\n",
    "max_images = 6  # Adjust based on your token calculations\n",
    "image_count = 0\n",
    "\n",
    "for image_file in image_files:\n",
    "    if image_count >= max_images:\n",
    "        break\n",
    "    image_path = os.path.join(FOLDER_PATH, image_file)\n",
    "    resized_image_path = resize_image(image_path)\n",
    "    base64_image = encode_image(resized_image_path)\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "        ]}\n",
    "    )\n",
    "    image_count += 1\n",
    "\n",
    "# Send the request to OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Print the generated MongoDB schema\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Function to save schema to a text file\n",
    "def save_schema_to_text(schema, collection_name):\n",
    "    output_path = os.path.join(FOLDER_PATH, f\"{collection_name}_schema.txt\")\n",
    "    with open(output_path, \"w\") as text_file:\n",
    "        text_file.write(schema)\n",
    "\n",
    "save_schema_to_text(response.choices[0].message.content, collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Set the API key and model name\u001b[39;00m\n\u001b[1;32m      7\u001b[0m MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the API key and model name\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "BASE_FOLDER_PATH = \"pdf_products\"\n",
    "API_KEY = os.environ.get(\"sqdc_api_key\")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Function to encode image as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to resize image proportionally\n",
    "def resize_image(image_path, output_folder):\n",
    "    resized_image_path = os.path.join(output_folder, f\"resized_{os.path.basename(image_path)}\")\n",
    "\n",
    "    if os.path.exists(resized_image_path):\n",
    "        return resized_image_path\n",
    "    \n",
    "    with Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "        if width <= 2000 and height <= 2000 and (width <= 768 or height <= 768):\n",
    "            return image_path  # No need to resize\n",
    "        \n",
    "        if width < height:\n",
    "            if width > 768:\n",
    "                ratio = 768 / width\n",
    "                new_width = 768\n",
    "                new_height = int(height * ratio)\n",
    "                if new_height > 2000:\n",
    "                    ratio = 2000 / height\n",
    "                    new_width = int(width * ratio)\n",
    "                    new_height = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        else:\n",
    "            if height > 768:\n",
    "                ratio = 768 / height\n",
    "                new_height = 768\n",
    "                new_width = int(width * ratio)\n",
    "                if new_width > 2000:\n",
    "                    ratio = 2000 / width\n",
    "                    new_height = int(height * ratio)\n",
    "                    new_width = 2000\n",
    "            else:\n",
    "                new_width, new_height = width, height\n",
    "        \n",
    "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        img.save(resized_image_path)\n",
    "        return resized_image_path\n",
    "\n",
    "# Function to process a folder\n",
    "def process_folder(folder_path):\n",
    "    # Get all .png files in the specified folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.png') and not f.startswith('resized_')]\n",
    "\n",
    "    # Encode images and create the messages list\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Vous êtes un assistant spécialiste des bases de données.\"}\n",
    "    ]\n",
    "    messages.append({\"role\": \"user\", \"content\": \"Analysez les images suivantes et extrayez le plus d'informations détaillées possible. Utilisez ces informations pour créer un schéma de validation MongoDB, même si le schéma n'est pas parfaitement structuré. Priorisez la richesse des données.\"})\n",
    "\n",
    "    max_images = max(3,len(image_files)*0.2)  \n",
    "    image_count = 0\n",
    "\n",
    "    for image_file in image_files:\n",
    "        if image_count >= max_images:\n",
    "            break\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        resized_image_path = resize_image(image_path, folder_path)\n",
    "        base64_image = encode_image(resized_image_path)\n",
    "        messages.append(\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "            ]}\n",
    "        )\n",
    "        image_count += 1\n",
    "\n",
    "    # Send the request to OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    # Print the generated MongoDB schema\n",
    "    schema = response.choices[0].message.content\n",
    "    print(schema)\n",
    "\n",
    "    # Function to save schema to a text file\n",
    "    def save_schema_to_text(schema, collection_name):\n",
    "        output_path = os.path.join(folder_path, f\"{collection_name}_schema.txt\")\n",
    "        with open(output_path, \"w\") as text_file:\n",
    "            text_file.write(schema)\n",
    "\n",
    "    save_schema_to_text(schema, os.path.basename(folder_path))\n",
    "\n",
    "# Process each subfolder within BASE_FOLDER_PATH\n",
    "for collection in os.listdir(BASE_FOLDER_PATH):\n",
    "    collection_path = os.path.join(BASE_FOLDER_PATH, collection)\n",
    "    if os.path.isdir(collection_path):\n",
    "        process_folder(collection_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atomiseurs Schema:\n",
      "{\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "        \"produit\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Nom du produit\"\n",
      "        },\n",
      "        \"marque\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Marque du produit\"\n",
      "        },\n",
      "        \"format\": {\n",
      "            \"type\": \"number\",\n",
      "            \"description\": \"Volume net du produit en ml\"\n",
      "        },\n",
      "        \"ingredients\": {\n",
      "            \"type\": \"array\",\n",
      "            \"items\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"description\": \"Liste des ingrédients\"\n",
      "        },\n",
      "        \"extraction\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Méthode d'extraction utilisée\"\n",
      "        },\n",
      "        \"dosage\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Dosage recommandé par activation\"\n",
      "        },\n",
      "        \"effets\": {\n",
      "            \"type\": \"array\",\n",
      "            \"items\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"description\": \"Effets potentiels du produit\"\n",
      "        },\n",
      "        \"temps_apparition\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Temps d'apparition des effets\"\n",
      "        },\n",
      "        \"production\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Informations sur la production du produit\"\n",
      "        },\n",
      "        \"mise_en_garde\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Mise en garde concernant l'utilisation\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"produit\",\n",
      "        \"marque\",\n",
      "        \"format\",\n",
      "        \"ingredients\",\n",
      "        \"extraction\",\n",
      "        \"dosage\",\n",
      "        \"effets\",\n",
      "        \"temps_apparition\"\n",
      "    ]\n",
      "}\n",
      "Autres Comestibles Schema:\n",
      "{\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "        \"produit\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"marque\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"format\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"ingredients\": {\n",
      "            \"type\": \"array\",\n",
      "            \"items\": {\n",
      "                \"type\": \"string\"\n",
      "            }\n",
      "        },\n",
      "        \"mode_de_consommation\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"caracteristiques\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"sans_thc\": {\n",
      "                    \"type\": \"boolean\"\n",
      "                },\n",
      "                \"vegan\": {\n",
      "                    \"type\": \"boolean\"\n",
      "                },\n",
      "                \"non_allergene\": {\n",
      "                    \"type\": \"boolean\"\n",
      "                },\n",
      "                \"sans_gluten\": {\n",
      "                    \"type\": \"boolean\"\n",
      "                },\n",
      "                \"sans_graisse\": {\n",
      "                    \"type\": \"boolean\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"effets_potentiels\": {\n",
      "            \"type\": \"array\",\n",
      "            \"items\": {\n",
      "                \"type\": \"string\"\n",
      "            }\n",
      "        },\n",
      "        \"temps_apparition_effets\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"avertissement\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"emballage\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"origine\": {\n",
      "            \"type\": \"string\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"produit\",\n",
      "        \"marque\",\n",
      "        \"format\",\n",
      "        \"ingredients\",\n",
      "        \"mode_de_consommation\",\n",
      "        \"caracteristiques\",\n",
      "        \"effets_potentiels\",\n",
      "        \"temps_apparition_effets\",\n",
      "        \"avertissement\",\n",
      "        \"emballage\",\n",
      "        \"origine\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_json_schema(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        start = lines.index('```json\\n') + 1\n",
    "        end = lines.index('```\\n', start)\n",
    "        json_schema = ''.join(lines[start:end])\n",
    "        return json.loads(json_schema)\n",
    "\n",
    "def convert_to_mongodb_schema(file_paths):\n",
    "    schemas = {}\n",
    "    for file_path in file_paths:\n",
    "        schema = extract_json_schema(file_path)\n",
    "        schema_name = file_path.split('/')[-1].split('_')[0]\n",
    "        schemas[schema_name] = schema\n",
    "    return schemas\n",
    "\n",
    "# Example usage:\n",
    "file_paths = [\n",
    "    'pdf_products/Atomiseurs/Atomiseurs_schema.txt',\n",
    "    'pdf_products/Autres Comestibles/Autres Comestibles_schema.txt'\n",
    "]\n",
    "\n",
    "mongodb_schemas = convert_to_mongodb_schema(file_paths)\n",
    "\n",
    "# Print the schemas\n",
    "for name, schema in mongodb_schemas.items():\n",
    "    print(f\"{name} Schema:\")\n",
    "    print(json.dumps(schema, indent=4, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
